{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to HDF5 (Part 1) \n",
    "\n",
    "## What's HDF5?\n",
    "\n",
    "* A file format optimized for numeric data\n",
    "* A hierarquichal structure to store information (like folders)\n",
    "* A self-describing container: Metadata + Data\n",
    "* A library with several functionalities (tools)\n",
    "* High level (user side): Easy access... Low level (machine side): binary, compressible\n",
    "* Fast I/O, parallel reading/writing (!), very good for HPC\n",
    "* Data can be read/written in chuncks, in-memory, out-of-memory  \n",
    "\n",
    "Read more: [https://www.hdfgroup.org/solutions/hdf5/](https://www.hdfgroup.org/solutions/hdf5/) \n",
    "\n",
    "## How popular is it?\n",
    "* Matlab `*.m` files **are** HDF5!\n",
    "* NetCDF4 files **are** HDF5!\n",
    "* ICESat-2 data comes in HDF5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write data to HDF5\n",
    "\n",
    "Let's create some fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.23717205  0.25636534 -1.2359709  -0.17819253  2.26250594 -0.15879622\n",
      "  0.62747877  0.25526599  0.76231598 -0.2713629   0.10103909  0.3495517\n",
      " -0.86866723 -0.88600418 -0.92267082 -0.28516992  0.95870646  1.0162589\n",
      " -0.85560512 -1.55958731 -1.78423422 -0.26889223 -1.63607843 -0.69690583\n",
      "  0.37373232  1.1960719   1.06556209 -0.15937085 -0.22890312  0.16366117\n",
      " -0.0274558  -0.04373179 -0.68112354  0.85488444 -0.19015823 -0.69716024\n",
      " -0.56649574 -1.01653546  0.92750811 -0.61027308 -0.06707487 -1.25289983\n",
      " -0.24523637  1.05107342 -0.2411199   1.13802961  1.37275758 -1.03295529\n",
      "  0.88266166 -0.19954122 -1.26767614 -0.72899013 -0.02941521 -0.20418557\n",
      " -0.69000116  0.13064206 -0.57239932  0.00364977  0.22776025 -0.10693565\n",
      "  1.34010888 -0.74704128 -1.90660117  0.22693056 -0.00422506 -1.18580822\n",
      " -1.42613459 -1.1770485  -0.13139396 -0.55537969  1.11065822  1.93605265\n",
      "  0.61310298 -1.01215765  0.74464929 -0.13421463 -1.28691168  0.06897178\n",
      "  0.49326126 -1.36131023 -0.98092924 -1.00327733  0.54849446 -0.47334044\n",
      "  1.11441597 -2.27654931  0.48331355  0.46889888  0.38584116 -0.36480761\n",
      " -0.16143729 -0.12089491  0.19276761  0.31354821 -0.60684352  1.53483105\n",
      " -0.49205944 -0.59647044 -2.03490401  0.42907179]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.randn(100)\n",
    "y = np.random.randn(100)\n",
    "z = np.random.randn(100)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save 1D arrays to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm myfile.h5                           # remove old file if previously written\n",
    "\n",
    "with h5py.File('myfile.h5', 'w') as f:  # open file in write mode\n",
    "    f['x'] = x                          # write data\n",
    "    f['y'] = y\n",
    "    f['z'] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myfile.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls *.h5  # Check the file was created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**  \n",
    "**The HDF5 library comes with some useful command-line tools**  \n",
    "**There is no need to write code to inspect an HDF5 file!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x                        Dataset {100}\r\n",
      "y                        Dataset {100}\r\n",
      "z                        Dataset {100}\r\n"
     ]
    }
   ],
   "source": [
    "!h5ls myfile.h5  # inspect the file w/command-line tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS: More sophysticated command-line tools below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from HDF5\n",
    "\n",
    "Load data (in memory) vs. get pointer (out of memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (in mem):  [-0.23717205  0.25636534 -1.2359709  -0.17819253  2.26250594 -0.15879622\n",
      "  0.62747877  0.25526599  0.76231598 -0.2713629   0.10103909  0.3495517\n",
      " -0.86866723 -0.88600418 -0.92267082 -0.28516992  0.95870646  1.0162589\n",
      " -0.85560512 -1.55958731 -1.78423422 -0.26889223 -1.63607843 -0.69690583\n",
      "  0.37373232  1.1960719   1.06556209 -0.15937085 -0.22890312  0.16366117\n",
      " -0.0274558  -0.04373179 -0.68112354  0.85488444 -0.19015823 -0.69716024\n",
      " -0.56649574 -1.01653546  0.92750811 -0.61027308 -0.06707487 -1.25289983\n",
      " -0.24523637  1.05107342 -0.2411199   1.13802961  1.37275758 -1.03295529\n",
      "  0.88266166 -0.19954122 -1.26767614 -0.72899013 -0.02941521 -0.20418557\n",
      " -0.69000116  0.13064206 -0.57239932  0.00364977  0.22776025 -0.10693565\n",
      "  1.34010888 -0.74704128 -1.90660117  0.22693056 -0.00422506 -1.18580822\n",
      " -1.42613459 -1.1770485  -0.13139396 -0.55537969  1.11065822  1.93605265\n",
      "  0.61310298 -1.01215765  0.74464929 -0.13421463 -1.28691168  0.06897178\n",
      "  0.49326126 -1.36131023 -0.98092924 -1.00327733  0.54849446 -0.47334044\n",
      "  1.11441597 -2.27654931  0.48331355  0.46889888  0.38584116 -0.36480761\n",
      " -0.16143729 -0.12089491  0.19276761  0.31354821 -0.60684352  1.53483105\n",
      " -0.49205944 -0.59647044 -2.03490401  0.42907179]\n",
      "y (on disk): <HDF5 dataset \"y\": shape (100,), type \"<f8\">\n",
      "\n",
      "x (in mem):  <class 'numpy.ndarray'>\n",
      "y (on disk): <class 'h5py._hl.dataset.Dataset'>\n",
      "\n",
      "x (in mem):  (100,)\n",
      "y (on disk): (100,)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('myfile.h5', 'r') as f:  # open file\n",
    "    x = f['x'][:]                       # read data into memory\n",
    "    y = f['y']                          # get pointer to data on disk\n",
    "    \n",
    "    print('x (in mem): ', x)\n",
    "    print('y (on disk):', y)\n",
    "    print('')\n",
    "    print('x (in mem): ', type(x))\n",
    "    print('y (on disk):', type(y))\n",
    "    print('')\n",
    "    print('x (in mem): ', x.shape)\n",
    "    print('y (on disk):', y.shape)  # same info from out-of-memory array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append data to HDF5\n",
    "\n",
    "Let's add some data with specific paths (groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('myfile.h5', 'a') as f:\n",
    "    f['/path/to/data/vec'] = z**2\n",
    "    f['/path/to/data/mat'] = z.reshape(10,10)\n",
    "    \n",
    "    # NOTE: 'path', 'to' and 'data' are groups\n",
    "    # 'vec' and 'mat' are datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/                        Group\r\n",
      "/path                    Group\r\n",
      "/path/to                 Group\r\n",
      "/path/to/data            Group\r\n",
      "/path/to/data/mat        Dataset {10, 10}\r\n",
      "/path/to/data/vec        Dataset {100}\r\n",
      "/x                       Dataset {100}\r\n",
      "/y                       Dataset {100}\r\n",
      "/z                       Dataset {100}\r\n"
     ]
    }
   ],
   "source": [
    "# Inspect file from the command line\n",
    "!h5ls -r myfile.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our HDF5 file has some structure!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add metadata to HDF5\n",
    "\n",
    "Let's first inpect the metadata added by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 \"myfile.h5\" {\r\n",
      "GROUP \"/\" {\r\n",
      "   GROUP \"path\" {\r\n",
      "      GROUP \"to\" {\r\n",
      "         GROUP \"data\" {\r\n",
      "            DATASET \"mat\" {\r\n",
      "               DATATYPE  H5T_IEEE_F64LE\r\n",
      "               DATASPACE  SIMPLE { ( 10, 10 ) / ( 10, 10 ) }\r\n",
      "            }\r\n",
      "            DATASET \"vec\" {\r\n",
      "               DATATYPE  H5T_IEEE_F64LE\r\n",
      "               DATASPACE  SIMPLE { ( 100 ) / ( 100 ) }\r\n",
      "            }\r\n",
      "         }\r\n",
      "      }\r\n",
      "   }\r\n",
      "   DATASET \"x\" {\r\n",
      "      DATATYPE  H5T_IEEE_F64LE\r\n",
      "      DATASPACE  SIMPLE { ( 100 ) / ( 100 ) }\r\n",
      "   }\r\n",
      "   DATASET \"y\" {\r\n",
      "      DATATYPE  H5T_IEEE_F64LE\r\n",
      "      DATASPACE  SIMPLE { ( 100 ) / ( 100 ) }\r\n",
      "   }\r\n",
      "   DATASET \"z\" {\r\n",
      "      DATATYPE  H5T_IEEE_F64LE\r\n",
      "      DATASPACE  SIMPLE { ( 100 ) / ( 100 ) }\r\n",
      "   }\r\n",
      "}\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "# Inspect Metadate from the commaand line\n",
    "!h5dump -H myfile.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add our own metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('myfile.h5', 'a') as f:\n",
    "    g = f['/path']               # pointer to group 'path'\n",
    "    d = f['/path/to/data/mat']   # pointer to dataset 'mat'\n",
    "    \n",
    "    # Metadata for the group\n",
    "    g.attrs['Description'] = 'This is a group'\n",
    "    g.attrs['Author'] = 'Your name'\n",
    "    g.attrs['email'] = 'yourname@domain.com'\n",
    "    \n",
    "    # Metadata for the data\n",
    "    d.attrs['Description'] = 'This is an array'\n",
    "    d.attrs['Date'] = '2019-06-01'\n",
    "    d.attrs['Version'] = '1.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 \"myfile.h5\" {\r\n",
      "GROUP \"/\" {\r\n",
      "   GROUP \"path\" {\r\n",
      "      ATTRIBUTE \"Author\" {\r\n",
      "         DATATYPE  H5T_STRING {\r\n",
      "            STRSIZE H5T_VARIABLE;\r\n",
      "            STRPAD H5T_STR_NULLTERM;\r\n",
      "            CSET H5T_CSET_UTF8;\r\n",
      "            CTYPE H5T_C_S1;\r\n",
      "         }\r\n",
      "         DATASPACE  SCALAR\r\n",
      "      }\r\n",
      "      ATTRIBUTE \"Description\" {\r\n",
      "         DATATYPE  H5T_STRING {\r\n",
      "            STRSIZE H5T_VARIABLE;\r\n",
      "            STRPAD H5T_STR_NULLTERM;\r\n",
      "            CSET H5T_CSET_UTF8;\r\n",
      "            CTYPE H5T_C_S1;\r\n",
      "         }\r\n",
      "         DATASPACE  SCALAR\r\n",
      "      }\r\n",
      "      ATTRIBUTE \"email\" {\r\n",
      "         DATATYPE  H5T_STRING {\r\n",
      "            STRSIZE H5T_VARIABLE;\r\n",
      "            STRPAD H5T_STR_NULLTERM;\r\n",
      "            CSET H5T_CSET_UTF8;\r\n",
      "            CTYPE H5T_C_S1;\r\n",
      "         }\r\n",
      "         DATASPACE  SCALAR\r\n",
      "      }\r\n",
      "      GROUP \"to\" {\r\n",
      "         GROUP \"data\" {\r\n",
      "            DATASET \"mat\" {\r\n",
      "               DATATYPE  H5T_IEEE_F64LE\r\n",
      "               DATASPACE  SIMPLE { ( 10, 10 ) / ( 10, 10 ) }\r\n",
      "               ATTRIBUTE \"Date\" {\r\n",
      "                  DATATYPE  H5T_STRING {\r\n",
      "                     STRSIZE H5T_VARIABLE;\r\n",
      "                     STRPAD H5T_STR_NULLTERM;\r\n",
      "                     CSET H5T_CSET_UTF8;\r\n",
      "                     CTYPE H5T_C_S1;\r\n",
      "                  }\r\n",
      "                  DATASPACE  SCALAR\r\n",
      "               }\r\n",
      "               ATTRIBUTE \"Description\" {\r\n",
      "                  DATATYPE  H5T_STRING {\r\n",
      "                     STRSIZE H5T_VARIABLE;\r\n",
      "                     STRPAD H5T_STR_NULLTERM;\r\n",
      "                     CSET H5T_CSET_UTF8;\r\n",
      "                     CTYPE H5T_C_S1;\r\n",
      "                  }\r\n",
      "                  DATASPACE  SCALAR\r\n",
      "               }\r\n",
      "               ATTRIBUTE \"Version\" {\r\n",
      "                  DATATYPE  H5T_STRING {\r\n",
      "                     STRSIZE H5T_VARIABLE;\r\n",
      "                     STRPAD H5T_STR_NULLTERM;\r\n",
      "                     CSET H5T_CSET_UTF8;\r\n",
      "                     CTYPE H5T_C_S1;\r\n",
      "                  }\r\n",
      "                  DATASPACE  SCALAR\r\n",
      "               }\r\n",
      "            }\r\n",
      "            DATASET \"vec\" {\r\n",
      "               DATATYPE  H5T_IEEE_F64LE\r\n",
      "               DATASPACE  SIMPLE { ( 100 ) / ( 100 ) }\r\n",
      "            }\r\n",
      "         }\r\n",
      "      }\r\n",
      "   }\r\n",
      "   DATASET \"x\" {\r\n",
      "      DATATYPE  H5T_IEEE_F64LE\r\n",
      "      DATASPACE  SIMPLE { ( 100 ) / ( 100 ) }\r\n",
      "   }\r\n",
      "   DATASET \"y\" {\r\n",
      "      DATATYPE  H5T_IEEE_F64LE\r\n",
      "      DATASPACE  SIMPLE { ( 100 ) / ( 100 ) }\r\n",
      "   }\r\n",
      "   DATASET \"z\" {\r\n",
      "      DATATYPE  H5T_IEEE_F64LE\r\n",
      "      DATASPACE  SIMPLE { ( 100 ) / ( 100 ) }\r\n",
      "   }\r\n",
      "}\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "# Inspect Metadata from the commaand line\n",
    "!h5dump -H myfile.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect HDF5 from Python\n",
    "\n",
    "Let's do the same as above but using Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['path', 'x', 'y', 'z']>\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File('myfile.h5', 'r')  # keep it open\n",
    "\n",
    "# Inspect base groups quickly\n",
    "print(f.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the full structure w/metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path\n",
      "    Author: Your name\n",
      "    Description: This is a group\n",
      "    email: yourname@domain.com\n",
      "path/to\n",
      "path/to/data\n",
      "path/to/data/mat\n",
      "    Date: 2019-06-01\n",
      "    Description: This is an array\n",
      "    Version: 1.2\n",
      "path/to/data/vec\n",
      "x\n",
      "y\n",
      "z\n"
     ]
    }
   ],
   "source": [
    "def print_attrs(name, obj):\n",
    "    print(name)\n",
    "    for key,val in obj.attrs.items():\n",
    "        print(\"    %s: %s\" % (key, val))\n",
    "\n",
    "f.visititems(print_attrs)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an extendable dataset\n",
    "\n",
    "Create an empty container (called `grids`) extendable in the 3rd dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm myfile.h5  # just in case\n",
    "\n",
    "with h5py.File('myfile.h5', 'a') as f:\n",
    "    dset = f.create_dataset(\"grids\", (10,10,5), maxshape=(10,10,None), dtype='f4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that our created container has an infinity dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/                        Group\r\n",
      "/grids                   Dataset {10, 10, 5/Inf}\r\n",
      "/path                    Group\r\n",
      "/path/to                 Group\r\n",
      "/path/to/data            Group\r\n",
      "/path/to/data/mat        Dataset {10, 10}\r\n",
      "/path/to/data/vec        Dataset {100}\r\n",
      "/x                       Dataset {100}\r\n",
      "/y                       Dataset {100}\r\n",
      "/z                       Dataset {100}\r\n"
     ]
    }
   ],
   "source": [
    "!h5ls -r myfile.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a bunch of 2D grids to save to our empty container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "mygrids = [np.random.randn(10,10) for _ in range(5)]\n",
    "\n",
    "print(np.shape(mygrids))  # 5 grids of 10 by 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save grids one at a time and close the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('myfile.h5', 'a') as f:\n",
    "    grids = f['grids']\n",
    "    \n",
    "    for k,g in enumerate(mygrids):\n",
    "        grids[:,:,k] = g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in (select) specific grids with fancy indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 3)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('myfile.h5', 'r') as f:\n",
    "    mygrids = f['grids'][:,:,[0,2,4]]  # 3 grids out of 5\n",
    "    \n",
    "print(np.shape(mygrids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADINJREFUeJzt3VuMXWUZxvHnYQ5tZ1oOpYBhWijEBkESAScI1EM4GFRULvQCDRK4sDcKBUlQvDF6TTyGYGpVNBBIrBAOUUQjaBDSOLQo0MFgANvSAj3QoR3oYWZeL2ZKEOvsNbC+vWb7/n8JCR02b97szr9rz3TtbxwRApDLYU0vAKD9CB9IiPCBhAgfSIjwgYQIH0iosfBtf8L2P2z/0/Y3mtqjKttLbD9ke9j207ZXNr1TFba7bK+3fX/Tu1Rh+0jba2w/M/Vcn9v0Tq3Yvm7qc+Ip23fYntv0Tq00Er7tLkk3S/qkpNMkfcH2aU3sMgNjkq6PiFMlnSPpKx2wsyStlDTc9BIz8ANJD0TE+yR9QLN8d9sDkq6RNBgRp0vqknRZs1u11tQV/2xJ/4yI5yJiv6Q7JV3a0C6VRMTWiFg39e+7NfkJOdDsVtOzvVjSJZJWN71LFbYPl/RRST+VpIjYHxG7mt2qkm5J82x3S+qTtKXhfVpqKvwBSZve8uvNmuURvZXtpZLOlLS22U1a+r6kGyRNNL1IRSdL2ibp51Nfnqy23d/0UtOJiBcl3SRpo6StkkYi4sFmt2qtqfB9iI91xL3DtudL+rWkayPitab3+V9sf1rSKxHxeNO7zEC3pLMk3RIRZ0oalTSrv/9j+yhNvlo9SdLxkvptX97sVq01Ff5mSUve8uvF6oCXR7Z7NBn97RFxV9P7tLBc0mdtv6DJL6UusH1bsyu1tFnS5og4+EpqjSb/IJjNLpL0fERsi4gDku6SdF7DO7XUVPh/lbTM9km2ezX5zZB7G9qlEtvW5NeewxHx3ab3aSUiboyIxRGxVJPP7x8jYlZfiSLiJUmbbJ8y9aELJW1ocKUqNko6x3bf1OfIhZrl35CUJl9atV1EjNn+qqTfafK7oD+LiKeb2GUGlkv6kqQnbT8x9bFvRsRvGtzp/9HVkm6fuiA8J+mqhveZVkSstb1G0jpN/s3Pekmrmt2qNfO2XCAf7twDEiJ8ICHCBxIifCAhwgcSajx82yua3mEmOm1fiZ3bodP2bTx8SR31hKnz9pXYuR06at/ZED6ANityA88RC7vjuIGeSo8d2TmmIxZWu4Fw0/ZF72ataUVftTewjb82qq7DZ8cbxrp3Vvtz+8C+PeqZM7/y3LG+d7pRC3Orv0lwps9zsfvQJg71frL/Nr57VF0LZvZ50b2n2uyZ2Ldnp8b2jrYcXOSW3eMGevTDe06qfe7XVn+59pkHjX9wd5m5Y+VeVB33qzIHvWz7QFeRufG+PUXmStLEeJnneWx3tQvYO3HsX+rPb8P936v0OF7qAwkRPpAQ4QMJET6QEOEDCVUKv9POwAcwvZbhd+gZ+ACmUeWK33Fn4AOYXpXwO/oMfAD/rUr4lc7At73C9pDtoZGdY+9+MwDFVAm/0hn4EbEqIgYjYrDqvfcAmlEl/I47Ax/A9Fpemjv0DHwA06j0mnzqh0bwgyOA/xPcuQckRPhAQoQPJET4QEKEDyRU5LDNvmOXxCmfu672uV17ax/5pihzzJz2Lqr/QMWD5p//cpG5L798ZJG5h20vd37dCQ8cKDJ3y0fmFJkrSfsG9tc+86Xv/Ej7Xtjc8pOOKz6QEOEDCRE+kBDhAwkRPpAQ4QMJET6QEOEDCRE+kBDhAwkRPpAQ4QMJET6QEOEDCRE+kBDhAwkRPpAQ4QMJET6QEOEDCRE+kBDhAwkV+UH2E73S7qX1z134VP1HgR905dfvKzL37tOOKTJXkj5yeZnzxn/x9/OLzB2fW+73b9ey3iJzu04fKTJXkg57o8DOh1V7jrniAwkRPpAQ4QMJET6QEOEDCRE+kBDhAwm1DN/2EtsP2R62/bTtle1YDEA5VW7gGZN0fUSss71A0uO2fx8RGwrvBqCQllf8iNgaEeum/n23pGFJA6UXA1DOjL7Gt71U0pmS1pZYBkB7VA7f9nxJv5Z0bUS8doj/vsL2kO2h8dHROncEULNK4dvu0WT0t0fEXYd6TESsiojBiBjs6u+vc0cANavyXX1L+qmk4Yj4bvmVAJRW5Yq/XNKXJF1g+4mpfz5VeC8ABbX867yIeESS27ALgDbhzj0gIcIHEiJ8ICHCBxIifCChIqfsztkxpvfeuq32uVsuPrb2mQfd9MTHy8x9dk2RuZL0y63nFpk7Pn+iyNyjT3y1yFxJ2rdxUZG5ezcuKDJXkq644M+1z/zJvGp3zXLFBxIifCAhwgcSInwgIcIHEiJ8ICHCBxIifCAhwgcSInwgIcIHEiJ8ICHCBxIifCAhwgcSInwgIcIHEiJ8ICHCBxIifCAhwgcSInwgoSLHa+89tkvDKxfWPrdnJGqfeVDX8/OKzP3mhiuKzJWkudvLPB/9F48UmbtzV3+RuZLUc0SZ5+Ki5X8rMleSbn3sw7XP3LHn8UqP44oPJET4QEKEDyRE+EBChA8kRPhAQoQPJFQ5fNtdttfbvr/kQgDKm8kVf6Wk4VKLAGifSuHbXizpEkmry64DoB2qXvG/L+kGSRMFdwHQJi3Dt/1pSa9ExLQ3AdteYXvI9tD4ntHaFgRQvypX/OWSPmv7BUl3SrrA9m1vf1BErIqIwYgY7Jpf7s0YAN69luFHxI0RsTgilkq6TNIfI+Ly4psBKIa/xwcSmtH78SPiYUkPF9kEQNtwxQcSInwgIcIHEiJ8ICHCBxIqcspu7y7pxPvqP/V06/LaR75p/8LxInMX7CjyFEuS3niPi8zd+2pfkbl9z/YWmStJb7ynzN3kD/3hjCJzJen5K2+pfebZN2+v9Diu+EBChA8kRPhAQoQPJET4QEKEDyRE+EBChA8kRPhAQoQPJET4QEKEDyRE+EBChA8kRPhAQoQPJET4QEKEDyRE+EBChA8kRPhAQkWOgB2fa+1a1lP73Dk7ax/5pi9+5pEic+8f+liRuZI01l/mlF2/3lVk7tHDY0XmSpKfKjP37G//tcxgSddvPav2mZsO7Kj0OK74QEKEDyRE+EBChA8kRPhAQoQPJET4QEKVwrd9pO01tp+xPWz73NKLASin6g08P5D0QER83navpDI/RxlAW7QM3/bhkj4q6UpJioj9kvaXXQtASVVe6p8saZukn9teb3u17f7CewEoqEr43ZLOknRLRJwpaVTSN97+INsrbA/ZHhp7Y7TmNQHUqUr4myVtjoi1U79eo8k/CP5DRKyKiMGIGOyexwsCYDZrGX5EvCRpk+1Tpj50oaQNRbcCUFTV7+pfLen2qe/oPyfpqnIrASitUvgR8YSkwcK7AGgT7twDEiJ8ICHCBxIifCAhwgcSInwgoTLHa/dIowNR+9yxheWOZ77nx2WOwZ63e6LIXEnSi2X+3D5mff2/d5I0cOOzReZK0t/vPbXI3Ie3LCsyV5Li7qNrn7l726OVHscVH0iI8IGECB9IiPCBhAgfSIjwgYQIH0iI8IGECB9IiPCBhAgfSIjwgYQIH0iI8IGECB9IiPCBhAgfSIjwgYQIH0iI8IGECB9IqMgpu93zxnTk+3fUPvfVZxbWPvOgXefsKzK398HeInMlaaTQAbBHrx8tMvfk/u1F5krSY0vLnMD8oUVbisyVpEeXLKp95kTFTzeu+EBChA8kRPhAQoQPJET4QEKEDyRE+EBClcK3fZ3tp20/ZfsO23NLLwagnJbh2x6QdI2kwYg4XVKXpMtKLwagnKov9bslzbPdLalPUrnbmQAU1zL8iHhR0k2SNkraKmkkIh4svRiAcqq81D9K0qWSTpJ0vKR+25cf4nErbA/ZHhobeb3+TQHUpspL/YskPR8R2yLigKS7JJ339gdFxKqIGIyIwe4j+ureE0CNqoS/UdI5tvtsW9KFkobLrgWgpCpf46+VtEbSOklPTv0/qwrvBaCgSu/Hj4hvSfpW4V0AtAl37gEJET6QEOEDCRE+kBDhAwkRPpBQkeO153Uf0OmLttY+90+9R9U+86D+J8u80/iVc8eLzJWkZaduLjJ302snFJn73G8/XGSuJOm4A0XGnrFgU5G5kvSnZfWfjx5zJio9jis+kBDhAwkRPpAQ4QMJET6QEOEDCRE+kBDhAwkRPpAQ4QMJET6QEOEDCRE+kBDhAwkRPpAQ4QMJET6QEOEDCRE+kBDhAwkRPpCQI6L+ofY2Sf+q+PBFkrbXvkQ5nbavxM7tMFv2PTEijmn1oCLhz4TtoYgYbHSJGei0fSV2bodO25eX+kBChA8kNBvCX9X0AjPUaftK7NwOHbVv41/jA2i/2XDFB9BmhA8kRPhAQoQPJET4QEL/BrZC2r6KGuAgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot each grid to check dimensions are right\n",
    "[plt.matshow(mygrids[:,:,k]) for k in range(mygrids.shape[2])]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final thoughts on HDF5\n",
    "\n",
    "- Many small files is usually more practical than a few large ones\n",
    "- Read/Write is faster on smaller files (faster queries)\n",
    "- Network transfer is usually faster with smaller files\n",
    "- Storing a lot of data into a single file is susceptible to corruption\n",
    "- Many small files simplifies (embarrasingly) parallelization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing ICESat-2 files (Part 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select files of interest (segment and time)\n",
    "* Select area of interest (subset lon)\n",
    "* Reduce selected files with variables of interest\n",
    "* Separate tracks into asc/des\n",
    "* Plot to check the files\n",
    "\n",
    "\n",
    "OBS: Using Kamb bounding box for now:\n",
    "\n",
    "xmin, xmax, ymin, ymax = [-1124782, 81623, -919821, -96334]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How ICESat-2 files are organized \n",
    "\n",
    "ICESat-2 ground tracks are subsetted into granules (individual files)\n",
    "\n",
    "Granules are then grouped into latitudinal bands (segments)\n",
    "\n",
    "![Segments](segments.png \"Latitudinal bands (Segments)\")\n",
    "\n",
    "\n",
    "File naming convention:\n",
    "\n",
    "`ATL06_20181120202321_08130101_001_01.h5`\n",
    "\n",
    "`ATL06_[yyyymmdd][hhmmss]_[RGTccss]_[vvv_rr].h5`\n",
    "\n",
    "where\n",
    "\n",
    "`ATL_06` => L3A Land Ice product    \n",
    "\n",
    "`yyyymmdd` => Year, month, day of data acquisition    \n",
    "\n",
    "`hhmmss` => Hour, minute, second of data acquisition   \n",
    "\n",
    "`RGT` => Reference Ground Track    \n",
    "\n",
    "`cc` => Cycle Number   \n",
    "\n",
    "`ss` => Segment number (latitude band)   \n",
    "\n",
    "`vvv_rr` => Version and revision numbers  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select files of interest\n",
    "\n",
    "We will use the **file name** info for this (no need to open the files).  \n",
    "\n",
    "Alternatively, we could retrieve this info from the **Metadata**.\n",
    "\n",
    "To select files withint a time interval and segment, all we need is:\n",
    "\n",
    "`yyyymmdd, hhmmss, ss`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's firt get a list with all file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files: 0\n"
     ]
    }
   ],
   "source": [
    "#from utils import *\n",
    "\n",
    "# Get file list from local folder\n",
    "if 1:\n",
    "    from glob import glob\n",
    "\n",
    "    files = glob('data/*.h5')\n",
    "    \n",
    "# Get file list from remote folder (through SSH)\n",
    "elif 0:    \n",
    "    import paramiko  # pip install paramiko\n",
    "\n",
    "    def list_files(host, user, pwd, cmd):\n",
    "        # Create an SSH client instance.\n",
    "        client = paramiko.SSHClient()\n",
    "\n",
    "        # Create a 'host_keys' object\n",
    "        # and load the local known hosts  \n",
    "        host_keys = client.load_system_host_keys()\n",
    "\n",
    "        # Connect to our client w/remote machine credentials\n",
    "        client.connect(host, username=user, password=pwd)\n",
    "\n",
    "        # Execute command on remote system,\n",
    "        # and get input, output and error variables\n",
    "        stdin, stdout, stderr = client.exec_command(cmd)\n",
    "\n",
    "        # Iterate over stdout\n",
    "        files = [line.strip('\\n') for line in stdout]\n",
    "\n",
    "        # Close the connection to client\n",
    "        client.close()\n",
    "        return files\n",
    "\n",
    "    host, user, pwd = 'devon.jpl.nasa.gov', 'paolofer', '********'  #FIXME: REMOVE PASSWORD!!!\n",
    "    cmd = 'ls /u/devon-r2/shared_data/icesat2/atl06/rel205/raw/*.h5'\n",
    "\n",
    "    files = list_files(host, user, pwd, cmd)\n",
    "    \n",
    "# Get file list from Amazon S3\n",
    "elif 0:\n",
    "    # Code here...\n",
    "    pass\n",
    "    \n",
    "print('Total number of files:', len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter file names by segment and time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "# File name format: ATL06_[yyyymmdd][hhmmss]_[RGTccss]_[vvv_rr].h5\n",
    "\n",
    "#NOTE: Need to simplify this function\n",
    "def time_from_fname(fname):\n",
    "    t = fname.split('_')[1]\n",
    "    y, m , d, h, mn, s = t[:4], t[4:6], t[6:8], t[8:10], t[10:12], t[12:14]\n",
    "    time = dt.datetime(int(y), int(m), int(d), int(h), int(mn), int(s))\n",
    "    return time\n",
    "\n",
    "\n",
    "def segment_from_fname(fname):\n",
    "    s = fname.split('_')[2]\n",
    "    return int(s[-2:])\n",
    "\n",
    "\n",
    "def select_files(files, segments=[10,11,12], t1=(2019,1,1), t2=(2019,2,1)):\n",
    "    t1 = dt.datetime(*t1)\n",
    "    t2 = dt.datetime(*t2)\n",
    "    files_out = []\n",
    "    for f in files:\n",
    "        fname = os.path.basename(f)\n",
    "        time = time_from_fname(fname)\n",
    "        segment = segment_from_fname(fname)\n",
    "        if t1 <= time <= t2 and segment in segments:\n",
    "            files_out.append(f)\n",
    "    return files_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/u/devon-r2/shared_data/icesat2/atl06/rel205/raw/ATL06_20190101001723_00540210_205_01.h5\n",
      "/u/devon-r2/shared_data/icesat2/atl06/rel205/raw/ATL06_20190101002504_00540211_205_01.h5\n",
      "/u/devon-r2/shared_data/icesat2/atl06/rel205/raw/ATL06_20190101003047_00540212_205_01.h5\n",
      "/u/devon-r2/shared_data/icesat2/atl06/rel205/raw/ATL06_20190101015140_00550210_205_01.h5\n",
      "/u/devon-r2/shared_data/icesat2/atl06/rel205/raw/ATL06_20190101015921_00550211_205_01.h5\n",
      "Number of files: 1388\n"
     ]
    }
   ],
   "source": [
    "files = select_files(files, segments=[10,11,12], t1=(2019,1,1), t2=(2019,2,1))\n",
    "\n",
    "for f in files[:5]: print(f)\n",
    "print('Number of files:', len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the selected files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for downloading selected files to -> data/\n",
    "# The files should already be dowloaded. This cell should not be executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce ICESat-2 files\n",
    "\n",
    "***\n",
    "**NOTE:** \n",
    "\n",
    "*This is neither the only nor the best way to handled ICESat-2 data files.*\n",
    "\n",
    "*This is **one** way that works well for large-scale processing (e.g. full continent) on parallel machines (e.g. HPC clusters).*\n",
    "\n",
    "*The idea is to (a) simplify the I/O of a complex workflow and (b) take advantage of embrrasingly parallelization.*\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the ICESat-2 file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/*.h5: unable to open file\r\n"
     ]
    }
   ],
   "source": [
    "!h5ls -r data/*.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's code a simple reader that:\n",
    "\n",
    "- Select variables of interest (x, y, t, h...)  \n",
    "- Filter data points based on quality flag and bbox   \n",
    "- Separate into beams and ascending/descending tracks  \n",
    "- Save data to a simpler HDF5 structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils import gps2dyr  <=== NOT WORKING!\n",
    "\n",
    "def read_atl06(ifile, bbox=None):\n",
    "    \"\"\" \n",
    "    Read 1 ATL06 file and output 12 reduced files. \n",
    "    \n",
    "    Extract variables of interest and separate the ATL06 file \n",
    "    into each beam (ground track) and ascending/descending orbits.\n",
    "    \"\"\"\n",
    "\n",
    "    # Each beam is a group\n",
    "    group = ['./gt1l','./gt1r','./gt2l','./gt2r','./gt3l','./gt3r']\n",
    "\n",
    "    # Loop trough beams\n",
    "    for k,g in enumerate(group):\n",
    "    \n",
    "        #-----------------------------------#\n",
    "        # 1) Read in data for a single beam #\n",
    "        #-----------------------------------#\n",
    "    \n",
    "        # Load variables into memory (more can be added!)\n",
    "        with h5py.File(ifile, 'r') as fi:\n",
    "            lat = fi[g+'/land_ice_segments/latitude'][:]\n",
    "            lon = fi[g+'/land_ice_segments/longitude'][:]\n",
    "            h_li = fi[g+'/land_ice_segments/h_li'][:]\n",
    "            s_li = fi[g+'/land_ice_segments/h_li_sigma'][:]\n",
    "            t_dt = fi[g+'/land_ice_segments/delta_time'][:]\n",
    "            flag = fi[g+'/land_ice_segments/atl06_quality_summary'][:]\n",
    "            s_fg = fi[g+'/land_ice_segments/fit_statistics/signal_selection_source'][:]\n",
    "            snr = fi[g+'/land_ice_segments/fit_statistics/snr_significance'][:]\n",
    "            h_rb = fi[g+'/land_ice_segments/fit_statistics/h_robust_sprd'][:]\n",
    "            dac = fi[g+'/land_ice_segments/geophysical/dac'][:]\n",
    "            f_sn = fi[g+'/land_ice_segments/geophysical/bsnow_conf'][:]\n",
    "            dh_fit_dx = fi[g+'/land_ice_segments/fit_statistics/dh_fit_dx'][:]\n",
    "            tide_earth = fi[g+'/land_ice_segments/geophysical/tide_earth'][:]\n",
    "            tide_load = fi[g+'/land_ice_segments/geophysical/tide_load'][:]\n",
    "            tide_ocean = fi[g+'/land_ice_segments/geophysical/tide_ocean'][:]\n",
    "            tide_pole = fi[g+'/land_ice_segments/geophysical/tide_pole'][:]\n",
    "            t_ref = fi['/ancillary_data/atlas_sdp_gps_epoch'][:]\n",
    "            rgt = fi['/orbit_info/rgt'][:] * np.ones(len(lat))\n",
    "\n",
    "        #---------------------------------------------#\n",
    "        # 2) Filter data according region and quality #\n",
    "        #---------------------------------------------#\n",
    "        \n",
    "        # Select a region of interest\n",
    "        if bbox:\n",
    "            lonmin, lonmax, latmin, latmax = bbox\n",
    "            bbox_mask = (lon >= lonmin) & (lon <= lonmax) & (lat >= latmin) & (lat <= latmax)\n",
    "        else:\n",
    "            bbox_mask = np.ones_like(lat, dtype=bool)  # get all\n",
    "            \n",
    "        # Only keep good data, and data inside bbox\n",
    "        mask = (flag == 0) & (np.abs(h_li) < 10e3) & (bbox_mask > 0)\n",
    "        \n",
    "        # Update variables\n",
    "        lat, lon, h_li, s_li, t_dt, h_rb, s_fg, snr, q_flag, f_sn, \\\n",
    "            tide_earth, tide_load, tide_ocean, tide_pole, dac, rgt = \\\n",
    "                lat[mask], lon[mask], h_li[mask],s_li[mask], t_dt[mask], h_rb[mask], \\\n",
    "                s_fg[mask], snr[mask], q_flag[mask], f_sn[mask], tide_earth[mask], \\\n",
    "                tide_load[mask], tide_ocean[mask], tide_pole[mask], dac[mask], rgt[mask]\n",
    "\n",
    "        # Test for no data\n",
    "        if len(h_li) == 0: return\n",
    "\n",
    "        #-------------------------------------#\n",
    "        # 3) Convert time and separate tracks #\n",
    "        #-------------------------------------#\n",
    "        \n",
    "        # Time in GPS seconds (secs sinde 1980...)\n",
    "        t_gps = t_ref + t_dt\n",
    "\n",
    "        # Time in decimal years\n",
    "        t_year = gps2dyr(t_gps)\n",
    "\n",
    "        # Determine orbit type\n",
    "        i_asc, i_des = track_type(t_year, lat)\n",
    "        \n",
    "        #-----------------------#\n",
    "        # 4) Save selected data #\n",
    "        #-----------------------#\n",
    "        \n",
    "        # Define output file name\n",
    "        ofile = ifile.replace('.h5', '_'+g[2:]+'.h5')\n",
    "        \n",
    "        #NOTE: Asc/Des can be saved in a single file w/index=0|1\n",
    "                \n",
    "        # Save ascending track data\n",
    "        if len(lat[i_asc]) > 1:\n",
    "            fasc = ofile.replace('.h5', '_A.h5')\n",
    "            with h5py.File(fasc, 'w') as fa:\n",
    "                fa['orbit'] = orb[i_asc][:]\n",
    "                fa['lon'] = lon[i_asc][:]\n",
    "                fa['lat'] = lat[i_asc][:]\n",
    "                fa['h_elv'] = h_li[i_asc][:]\n",
    "                fa['s_elv'] = s_li[i_asc][:]\n",
    "                fa['t_year'] = t_li[i_asc][:]\n",
    "                fa['h_rb'] = h_rb[i_asc][:]\n",
    "                fa['s_fg'] = s_fg[i_asc][:]\n",
    "                fa['snr'] = snr[i_asc][:]\n",
    "                fa['q_flg'] = q_flag[i_asc][:]\n",
    "                fa['f_sn'] = f_sn[i_asc][:]\n",
    "                fa['t_sec'] = t_gps[i_asc][:]\n",
    "                fa['tide_load'] = tide_load[i_asc][:]\n",
    "                fa['tide_ocean'] = tide_ocean[i_asc][:]\n",
    "                fa['tide_pole'] = tide_pole[i_asc][:]\n",
    "                fa['tide_earth'] = tide_earth[i_asc][:]\n",
    "                fa['dac'] = dac[i_asc][:]\n",
    "                fa['rgt'] = rgt[i_asc][:]                \n",
    "\n",
    "                print('asc ->', fasc)\n",
    "\n",
    "        # Save desending track data\n",
    "        if len(lat[i_des]) > 1:\n",
    "            fdes = ofile.replace('.h5', '_D.h5')\n",
    "            with h5py.File(fdes, 'w') as fd:\n",
    "                fd['orbit'] = orb[i_des][:]\n",
    "                fd['lon'] = lon[i_des][:]\n",
    "                fd['lat'] = lat[i_des][:]\n",
    "                fd['h_elv'] = h_li[i_des][:]\n",
    "                fd['s_li'] = s_li[i_des][:]\n",
    "                fd['t_year'] = t_li[i_des][:]\n",
    "                fd['h_rb'] = h_rb[i_des][:]\n",
    "                fd['s_fg'] = s_fg[i_des][:]\n",
    "                fd['snr'] = snr[i_des][:]\n",
    "                fd['q_flg'] = q_flag[i_des][:]\n",
    "                fd['f_sn'] = f_sn[i_des][:]\n",
    "                fd['t_sec'] = t_gps[i_des][:]\n",
    "                fd['tide_load'] = tide_load[i_des][:]\n",
    "                fd['tide_ocean'] = tide_ocean[i_des][:]\n",
    "                fd['tide_pole'] = tide_pole[i_des][:]\n",
    "                fd['tide_earth'] = tide_earth[i_des][:]\n",
    "                fd['dac'] = dac[i_des][:]\n",
    "                fd['rgt'] = rgt[i_des][:]\n",
    "                \n",
    "                print('des ->', fdes)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Merge beams for crossover analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running in parallel (16 jobs) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   0 out of   0 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "njobs = 16\n",
    "files = []\n",
    "\n",
    "if njobs == 1:\n",
    "    print('running in serial ...')\n",
    "    [read_atl06(f) for f in files]\n",
    "\n",
    "else:\n",
    "    print('running in parallel (%d jobs) ...' % njobs)\n",
    "    from joblib import Parallel, delayed\n",
    "    Parallel(n_jobs=njobs, verbose=5)(delayed(read_atl06)(f) for f in files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our created files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: data/*.h5: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/*.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/*gt2r_A.h5: unable to open file\r\n"
     ]
    }
   ],
   "source": [
    "!h5ls -r data/*gt2r_A.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some data to check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot points within region to check (map and scatter)\n",
    "* Plot tracks/beams to check (map and profiles)\n",
    "* Show single program with all of the above in one go (`readatl06.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
