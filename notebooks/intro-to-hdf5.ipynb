{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to HDF5 data model\n",
    "\n",
    "* High-level overview of the HDF5 file strudcture and basic tools\n",
    "\n",
    "\n",
    "## What's HDF5?\n",
    "\n",
    "* HDF5 = Hierarchical Data Format Version 5\n",
    "* A file format optimized for numeric data\n",
    "* A hierarquichal structure to store information (like folders)\n",
    "* A self-describing container: Metadata + Data\n",
    "* A library with several functionalities (tools)\n",
    "* High level from user side (easy access) / Low level from machine side (binary, compressible)\n",
    "* Fast I/O, parallel reading/writing (!), very good for HPC\n",
    "* Data can be read/written in chuncks, in-memory, out-of-memory  \n",
    "\n",
    "Read more: [https://www.hdfgroup.org/solutions/hdf5/](https://www.hdfgroup.org/solutions/hdf5/) \n",
    "\n",
    "## How popular is it?\n",
    "* Matlab `*.m` files **are** HDF5!\n",
    "* NetCDF4 files **are** HDF5!\n",
    "* ICESat-2 data comes in HDF5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write data to HDF5\n",
    "\n",
    "Let's create some fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.randn(100)\n",
    "y = np.random.randn(100)\n",
    "z = np.random.randn(100)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save 1D arrays to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm myfile.h5                           # remove old file if previously written\n",
    "#!rm data/*_gt*                          # remove existing data just in case\n",
    "\n",
    "with h5py.File('myfile.h5', 'w') as f:  # open file in write mode\n",
    "    f['x'] = x                          # write data\n",
    "    f['y'] = y\n",
    "    f['z'] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.h5  # Check the file was created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**  \n",
    "**The HDF5 library comes with some useful command-line tools**  \n",
    "**There is no need to write code to inspect an HDF5 file!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!h5ls myfile.h5  # inspect the file w/command-line tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS: More sophysticated command-line tools below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from HDF5\n",
    "\n",
    "Load data (in memory) vs. get pointer (out of memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('myfile.h5', 'r') as f:  # open file\n",
    "    x = f['x'][:]                       # read data into memory\n",
    "    y = f['y']                          # get pointer to data on disk\n",
    "    \n",
    "    print('x (in mem): ', x)\n",
    "    print('y (on disk):', y)\n",
    "    print('')\n",
    "    print('x (in mem): ', type(x))\n",
    "    print('y (on disk):', type(y))\n",
    "    print('')\n",
    "    print('x (in mem): ', x.shape)\n",
    "    print('y (on disk):', y.shape)  # same info from out-of-memory array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append data to HDF5\n",
    "\n",
    "Let's add some data with specific paths (groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('myfile.h5', 'a') as f:\n",
    "    f['/path/to/data/vec'] = z**2\n",
    "    f['/path/to/data/mat'] = z.reshape(10,10)\n",
    "    \n",
    "    # NOTE: 'path', 'to' and 'data' are groups\n",
    "    # 'vec' and 'mat' are datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect file from the command line\n",
    "!h5ls -r myfile.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our HDF5 file has some structure!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add metadata to HDF5\n",
    "\n",
    "Let's first inpect the metadata added by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect Metadate from the commaand line\n",
    "!h5dump -H myfile.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add our own metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('myfile.h5', 'a') as f:\n",
    "    g = f['/path']               # pointer to group 'path'\n",
    "    d = f['/path/to/data/mat']   # pointer to dataset 'mat'\n",
    "    \n",
    "    # Metadata for the group\n",
    "    g.attrs['Description'] = 'This is a group'\n",
    "    g.attrs['Author'] = 'Your name'\n",
    "    g.attrs['email'] = 'yourname@domain.com'\n",
    "    \n",
    "    # Metadata for the data\n",
    "    d.attrs['Description'] = 'This is an array'\n",
    "    d.attrs['Date'] = '2019-06-01'\n",
    "    d.attrs['Version'] = '1.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect Metadata from the commaand line\n",
    "!h5dump -H myfile.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect HDF5 from Python\n",
    "\n",
    "Let's do the same as above but using Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('myfile.h5', 'r')  # keep it open\n",
    "\n",
    "# Inspect base groups quickly\n",
    "print(f.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the full structure w/metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_attrs(name, obj):\n",
    "    print(name)\n",
    "    for key,val in obj.attrs.items():\n",
    "        print(\"    %s: %s\" % (key, val))\n",
    "\n",
    "f.visititems(print_attrs)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an extendable dataset\n",
    "\n",
    "Create an empty container (called `grids`) extendable in the 3rd dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('myfile.h5', 'a') as f:\n",
    "    dset = f.create_dataset(\"grids\", (10,10,5), maxshape=(10,10,None), dtype='f4', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that our created container has an infinity dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!h5ls -r myfile.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a bunch of 2D grids to save to our empty container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygrids = [np.random.randn(10,10) for _ in range(5)]\n",
    "\n",
    "print(np.shape(mygrids))  # 5 grids of 10 by 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save grids one at a time and close the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('myfile.h5', 'a') as f:\n",
    "    grids = f['grids']\n",
    "    \n",
    "    for k,g in enumerate(mygrids):\n",
    "        grids[:,:,k] = g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in (select) specific grids with fancy indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('myfile.h5', 'r') as f:\n",
    "    mygrids = f['grids'][:,:,[0,2,4]]  # 3 grids out of 5\n",
    "    \n",
    "print(np.shape(mygrids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot each grid to check dimensions are right\n",
    "[plt.matshow(mygrids[:,:,k]) for k in range(mygrids.shape[2])]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final thoughts on HDF5\n",
    "\n",
    "- Many small files is usually more practical than a few large ones\n",
    "- Read/Write is faster on smaller files (faster queries)\n",
    "- Network transfer is usually faster with smaller files\n",
    "- Storing a lot of data into a single file is susceptible to corruption\n",
    "- Many small files simplifies (embarrasingly) parallelization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
